{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpack Kaggle Competition\n",
    "### W207 Final Project - Spring 2025\n",
    "\n",
    "Team: Perry Gabriel, Aurelia Yang\n",
    "\n",
    "University of California, Berkeley\n",
    "\n",
    "## Description\n",
    "\n",
    "In this competition, participants are challenged to develop machine learning models to predict the price of a backpack based on various features. This is a great opportunity to test your skills, learn new techniques, and compete with others in the data science community.\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "Submissions are evaluated on the root mean squared error between the predicted and actual price of the backpack.\n",
    "\n",
    "RMSE is defined as:\n",
    "$$ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} $$\n",
    "\n",
    "where $y_i$ is the actual price of the backpack and $\\hat{y}_i$ is the predicted price of the backpack.\n",
    "\n",
    "## Data Description\n",
    "\n",
    "The data consists of the following columns:\n",
    "\n",
    "- `id`: A unique identifier for the backpack.\n",
    "- `Brand`: The brand of the backpack.\n",
    "- `Material`: The material of the backpack.\n",
    "- `Size`: The size of the backpack.\n",
    "- `Compartments`: The number of compartments in the backpack.\n",
    "- `Laptop Compartment`: Whether the backpack has a laptop compartment.\n",
    "- `Waterproof`: Whether the backpack is waterproof.\n",
    "- `Style`: The style of the backpack.\n",
    "- `Color`: The color of the backpack.\n",
    "- `Weight Capacity (kg)`: The weight capacity of the backpack in kilograms.\n",
    "- `Price`: The price of the backpack.\n",
    "\n",
    "## Submission File\n",
    "\n",
    "For each `id` in the test set, you must predict the price of the backpack. The file should contain a header and have the following format:\n",
    "\n",
    "```python\n",
    "id,Price\n",
    "1,100\n",
    "2,200\n",
    "3,300\n",
    "```\n",
    "\n",
    "## Timeline\n",
    "\n",
    "- **Start Date** - February 1, 2025\n",
    "- **Entry Deadline** - Same as the Final Submission Deadline\n",
    "- **Team Merger Deadline** - Same as the Final Submission Deadline\n",
    "- **Final Submission Deadline** - February 28, 2025\n",
    "\n",
    "All deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "This dataset was created by [Kaggle](https://www.kaggle.com/datasets/souradippal/student-bag-price-prediction-dataset) for the purpose of hosting a competition.\n",
    "\n",
    "## Team Members\n",
    "\n",
    "- [Perry Gabriel](https://www.kaggle.com/prgabriel)\n",
    "- [Aurelia Yang](https://www.kaggle.com/aureliayang)\n",
    "\n",
    "## Sections\n",
    "\n",
    "1. [Exploratory Data Analysis](#1.-Exploratory-Data-Analysis)\n",
    "2. [Data Preprocessing](#2.-Data-Preprocessing)\n",
    "3. [Modeling](#3.-Modeling)\n",
    "4. [Evaluation](#4.-Evaluation)\n",
    "5. [Optimization](#5.-Optimization)\n",
    "6. [Final Submission](#6.-Final-Submission)\n",
    "7. [Conclusion](#7.-Conclusion)\n",
    "\n",
    "## References\n",
    "[Backpack Kaggle Competition Link](https://www.kaggle.com/competitions/playground-series-s5e2)\n",
    "\n",
    "[Backpack Kaggle Competition Dataset](https://www.kaggle.com/datasets/souradippal/student-bag-price-prediction-dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Data Analysis\n",
    "\n",
    "In this section, we will explore the data to understand its structure and identify any patterns or trends that may be present.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load the Data\n",
    "\n",
    "Let's start by loading the data and taking a look at the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) #used to supress the tf version warning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = '../data/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google.colab\n",
    "\n",
    "def check_and_import_colab():\n",
    "    global raw_data_path\n",
    "    global processed_path\n",
    "    try:\n",
    "        from google.colab import drive  \n",
    "        import google.colab\n",
    "        print(\"Running on Google Colab\")\n",
    "        # Import necessary libraries for Google Colab\n",
    "        drive.mount('/content/drive')\n",
    "\n",
    "        # define paths\n",
    "        raw_data_path = \"/content/drive/MyDrive/Kaggle_Backpack/data/raw/\"\n",
    "        processed_path = \"/content/drive/MyDrive/Kaggle_Backpack/data/processed/\"\n",
    "        return True\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"Not running on Google Colab\")\n",
    "        os.makedirs(raw_data_path, exist_ok=True)\n",
    "        print(\"Created 'raw_data_path' directory for non-Colab Environment.\")\n",
    "        return False\n",
    "\n",
    "on_colab = check_and_import_colab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment to download the data from Kaggle. This assumes you have the Kaggle API installed and configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c playground-series-s5e2\n",
    "# !unzip playground-series-s5e2 -d ../data/raw/\n",
    "# !pip install -r ../requirements.txt\n",
    "# !rm -rf playground-series-s5e2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/05 00:43:50 INFO mlflow.tracking.fluent: Experiment with name '/E2E_Kaggle_Backpack_Project' does not exist. Creating a new experiment.\n",
      "2025/03/05 00:43:50 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/03/05 00:43:50 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_name='/E2E_Kaggle_Backpack_Project')\n",
    "mlflow.set_tracking_uri(\"colab\")\n",
    "mlflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(filepath_or_buffer=os.path.join(raw_data_path, 'train.csv'), index_col=0, header=0, sep=',')\n",
    "test_df = pd.read_csv(filepath_or_buffer=os.path.join(raw_data_path, 'test.csv'), index_col=0, header=0, sep=',')\n",
    "train_extra_df = pd.read_csv(filepath_or_buffer=os.path.join(raw_data_path, 'training_extra.csv'), index_col=0, header=0, sep=',')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_extra_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Summary\n",
    "\n",
    "Next, let's take a look at the summary statistics of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the summary statistics of the training data\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_extra_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the data types of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data types of columns in training dataset\\n{train_df.dtypes}\\n\")\n",
    "print(f\"Data types of columns in training extra dataset\\n{train_extra_df.dtypes}\\n\")\n",
    "print(f\"Data types of columns in testing dataset\\n{test_df.dtypes}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the shape of the dataset.\n",
    "print(f\"Shape of training data: {train_df.shape}\")\n",
    "print(f\"Shape of training extra data: {train_extra_df.shape}\")\n",
    "print(f\"Shape of testing data: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Visualization\n",
    "\n",
    "We can also create visualizations to better understand the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot of the training data\n",
    "sns.pairplot(train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot of the training extra data\n",
    "sns.pairplot(train_extra_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, plot a histogram of the price column\n",
    "plt.hist(train_df['Price'], bins=20, edgecolor='black')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Price (train_df)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, plot a histogram of the price column\n",
    "plt.hist(train_extra_df['Price'], bins=20, edgecolor='black')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Price (train_extra_df)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Correlation Matrix\n",
    "\n",
    "Finally, let's create a correlation matrix to see how the features are related to each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the numeric columns\n",
    "numeric_cols = train_df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Create a correlation matrix\n",
    "corr = numeric_cols.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations so far: \n",
    "\n",
    "- `training_extra` has significantly more records (3.69M) than `training` (300k), which will be useful in improving model training.\n",
    "- Some categorical columns have substantial missing values:\n",
    "    - `Brand`: 9705 missing in `train`, 117,000 missing in `train_extra`\n",
    "    - `Material`, `Style`, `Color`\n",
    "- `train_extra` has a higher proportion of missing values.\n",
    "- Considering:\n",
    "    - Mode imputation for categorical columns\n",
    "    - Mean/median imputation for numerical columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Feature Distribution\n",
    "\n",
    "Let's take a look at the distribution of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define numerical and categorical cols\n",
    "num_cols = train_df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "cat_cols = train_df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# remove price\n",
    "num_cols.remove('Price')\n",
    "\n",
    "# feature distribution comparison train.csv vs train_extra.csv\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.kdeplot(train_df['Price'], label='Train', fill=True)\n",
    "sns.kdeplot(train_extra_df['Price'], label='Train Extra', fill=True)\n",
    "plt.legend()\n",
    "plt.title(\"Price Distribution Comparison (Train vs Train Extra)\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n",
    "\n",
    "# outlier boxplots\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x=train_df[\"Price\"])\n",
    "plt.title(\"Boxplot of Backpack Prices\")\n",
    "plt.show()\n",
    "\n",
    "# categorical feature distribution\n",
    "for col in cat_cols:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.countplot(y=train_df[col], order=train_df[col].value_counts().index, hue=train_df[col], palette=\"coolwarm\", legend=False)\n",
    "    plt.title(f\"Count Plot of {col}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations: Data Loading and Preprocessing\n",
    "\n",
    "#### Price Distribution (train vs train extra)\n",
    "- Both datasets are similarly distributed.\n",
    "\n",
    "#### Outlier Analysis\n",
    "- Slightly right-skewed distribution.\n",
    "- Consider removing outliers?\n",
    "\n",
    "#### Correlation Matrix\n",
    "- Weight capacity is slightly positively correlated with price (0.2).\n",
    "- Categorical feature impact on price needs boxplots by category -> build this out.\n",
    "\n",
    "#### Categorical Feature Distribution\n",
    "- No glaring abnormalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "In this section, we will preprocess the data to prepare it for modeling.\n",
    "\n",
    "### 2.1 Missing Values\n",
    "\n",
    "First, let's check for missing values in the data and decide how to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_extra_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fill in missing values categorical values with mode and numerical values with forward fill for both training datasets and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine train and train_extra\n",
    "train_combined = pd.concat([train_df, train_extra_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "# fill categorical with mode, others forward fill\n",
    "for col in cat_cols:\n",
    "    train_combined[col] = train_combined[col].fillna(train_combined[col].mode()[0])\n",
    "test_df = test_df.ffill()\n",
    "\n",
    "for col in num_cols:\n",
    "    train_combined[col] = train_combined[col].fillna(train_combined[col].median())\n",
    "test_df[num_cols] = test_df[num_cols].fillna(test_df[num_cols].median())\n",
    "\n",
    "# one-hot encode (nominal categorical features)\n",
    "ohe_cols = ['Brand', 'Color', 'Style']\n",
    "train_encoded_df = pd.get_dummies(train_combined, columns=ohe_cols, drop_first=True)\n",
    "test_encoded_df = pd.get_dummies(test_df, columns=ohe_cols, drop_first=True)\n",
    "\n",
    "# ensure test set has same features as train\n",
    "train_cols = train_encoded_df.columns\n",
    "test_encoded_df = test_encoded_df.reindex(columns=train_cols, fill_value=0)\n",
    "\n",
    "# ordinal feature label encoding\n",
    "le_cols = ['Material', 'Size']\n",
    "le = LabelEncoder()\n",
    "for col in le_cols:\n",
    "    train_encoded_df[col] = le.fit_transform(train_combined[col])\n",
    "    test_encoded_df[col] = le.transform(test_df[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Feature Engineering\n",
    "\n",
    "In this section, we will create new features that may help improve the performance of our models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering - interaction terms\n",
    "train_encoded_df[\"Price_per_Compartment\"] = train_encoded_df[\"Price\"] / (train_encoded_df[\"Compartments\"] + 1)\n",
    "train_encoded_df[\"Has_Laptop_Compartment\"] = train_encoded_df[\"Laptop Compartment\"].apply(lambda x: 1 if x == \"Yes\" else 0)\n",
    "\n",
    "# standardization (scale numerical features)\n",
    "scaler = StandardScaler()\n",
    "train_encoded_df[num_cols] = scaler.fit_transform(train_encoded_df[num_cols])\n",
    "test_encoded_df[num_cols] = scaler.transform(test_encoded_df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see the changes\n",
    "train_encoded_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets save the data to a new csv file under processed_data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks to see if this notebook is running on Google Colab and save to the recommended locations. \n",
    "if on_colab:\n",
    "    # save processed data to drive\n",
    "    train_encoded_df.to_csv(os.path.join(processed_path, \"train_final.csv\"), index=False)\n",
    "    test_encoded_df.to_csv(os.path.join(processed_path, \"test_final.csv\"), index=False)\n",
    "    print(\"Feature engineering completed - processed files saved on Google Drive.\")\n",
    "else:\n",
    "    # Check if the directory exists, if not, create it\n",
    "    processed_file_path = '../data/processed'\n",
    "    if not os.path.exists(processed_file_path):\n",
    "        os.makedirs(processed_file_path)\n",
    "\n",
    "    # Save the transformed training data\n",
    "    train_encoded_df.to_csv(processed_file_path + '/train_processed.csv', index=True)\n",
    "    processed_train_encoded_df = train_encoded_df.copy()\n",
    "\n",
    "    # Save the transformed testing data\n",
    "    test_encoded_df.to_csv(processed_file_path + '/test_processed.csv', index=True)\n",
    "    processed_test_encoded_df = test_encoded_df.copy()\n",
    "    print(\"Feature engineering completed - processed files saved to Non-Colab Environment Local Drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations so far ###\n",
    "- Merged train and train_extra datasets\n",
    "- Dropped id column\n",
    "- OHE for brand, color and style\n",
    "- Performed label encoding for material and size columns\n",
    "- Added feature interactions\n",
    "  - price_per_compartment, has_laptop_compartment\n",
    "- mode imputation for categorical columns missing vals\n",
    "- forward fill for numerical columns missing vals\n",
    "- saved processed data to processed_data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling\n",
    "\n",
    "In this section, we will select and train machine learning models to predict the price of the backpack.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if on_colab:\n",
    "    train_final_df = pd.read_csv(os.path.join(processed_path, \"train_final.csv\"))\n",
    "    test_final_df = pd.read_csv(os.path.join(processed_path, \"test_final.csv\"))\n",
    "\n",
    "    print(\"Train Final Shape:\", train_final_df.shape)\n",
    "    print(\"Test Final Shape:\", test_final_df.shape)\n",
    "\n",
    "    display(train_final_df.head(3))\n",
    "    display(test_final_df.head(3))\n",
    "else:\n",
    "    train_final_df = pd.read_csv(os.path.join(processed_file_path, \"train_processed.csv\"))\n",
    "    test_final_df = pd.read_csv(os.path.join(processed_file_path, \"test_processed.csv\"))\n",
    "\n",
    "    print(\"Train Final Shape:\", train_final_df.shape)\n",
    "    print(\"Test Final Shape:\", test_final_df.shape)\n",
    "\n",
    "    display(train_final_df.head())\n",
    "    display(test_final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'id' and 'Unnamed: 0' columns from the datasets\n",
    "train_final_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "test_final_df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Verify the changes\n",
    "print(train_final_df.head())\n",
    "print(test_final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Price' column is present before dropping\n",
    "if 'Price' in train_final_df.columns:\n",
    "\t# Select the target feature\n",
    "\ty = train_final_df['Price']\n",
    "\n",
    "\t# Drop the target feature from the training dataframe\n",
    "\tX = train_final_df.drop(columns=['Price'])\n",
    "\n",
    "\t# Verify the changes\n",
    "\tprint(X.head())\n",
    "\tprint(y.head())\n",
    "else:\n",
    "\tprint(\"'Price' column is not present in train_final_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of X, and y\n",
    "print(f\"X Shape: {X.shape}\")\n",
    "print(f\"y Shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leftover cat cols\n",
    "obj_cols = X.select_dtypes(include=['object']).columns\n",
    "print(\"Object columns:\", obj_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Train-Test Split\n",
    "\n",
    "First, let's split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# convert cat to numerical\n",
    "X_train[\"Laptop Compartment\"] = X_train[\"Laptop Compartment\"].map({\"Yes\": 1, \"No\": 0})\n",
    "X_train[\"Waterproof\"] = X_train[\"Waterproof\"].map({\"Yes\": 1, \"No\": 0})\n",
    "X_val[\"Laptop Compartment\"] = X_val[\"Laptop Compartment\"].map({\"Yes\": 1, \"No\": 0})\n",
    "X_val[\"Waterproof\"] = X_val[\"Waterproof\"].map({\"Yes\": 1, \"No\": 0})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model Selection\n",
    "\n",
    "Next, let's select a model to train on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model\n",
    "lr_model = LinearRegression().fit(X_train, y_train)\n",
    "lr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation\n",
    "\n",
    "In this section, we will evaluate the performance of our models using various metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our y_hat value with y_pred_lr variable.\n",
    "y_pred_lr = lr_model.predict(X_val)\n",
    "\n",
    "rmse_lr = root_mean_squared_error(y_val, y_pred_lr)\n",
    "print(\"Baseline Linear Regression RMSE:\", rmse_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "residuals = y_val - y_pred_lr\n",
    "\n",
    "# Plot baseline and residuals\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_val, y_pred_lr, alpha=0.3)\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Baseline Model: Predicted vs Actual Price')\n",
    "plt.show()\n",
    "\n",
    "# Plot distribution of residuals\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(residuals, kde=True, bins=30)\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "#### Residual Distribution\n",
    "- There is a large spike near residual = 0, indicating that, on average, the baseline model predictions are close to the actual price for many backpacks.\n",
    "- Wide spread, heavy tails: Residuals extend from about -60 to +60, suggesting that for some backpacks, the baseline model underpredicts by up to 60 units and overpredicts by up to 60 units. A high variance in residuals suggests significant differences in how well the linear baseline model captures the data across different price ranges/categories.\n",
    "- RMSE is very high: 25.03. While many predictions cluster around 0, there is still a lot of deviation.\n",
    "\n",
    "#### Predicted vs Actual Price\n",
    "- Points spread out well above and below the diagonal, meaning the baseline model error is not constant across the price range. The baseline model may overestimate some backpack prices (points above the red line) and underestimate others (points below the red line).\n",
    "- There are multiple lines in the predicted values, indicating that the linear baseline model is grouping certain types of backpacks (perhaps by brand, color, or other splits) and producing similar predictions for them. This effect is more pronounced in linear baseline models when strong interactions are not fully captured.\n",
    "\n",
    "#### Overall\n",
    "- The baseline captures some positive relationship, but there is significant variance in the predictions with clear clusters at certain price ranges. The high error spread suggests the relationship cannot be captured by a simple linear baseline model and certain features may be missing.\n",
    "- The multiple lines indicate that combining certain features leads to the same predicted price, so we may explore adding more interaction terms or exploring a non-linear baseline model next, such as a random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 5. Model Optimization\n",
    "\n",
    "In this section, we will optimize the hyperparameters of our models to improve their performance.\n",
    "\n",
    "\n",
    "## 6. Final Submission\n",
    "\n",
    "In this section, we will select the best model and make final predictions on the test set.\n",
    "\n",
    "\n",
    "## 7. Conclusion\n",
    "\n",
    "In this section, we will summarize our findings and discuss the implications of our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
