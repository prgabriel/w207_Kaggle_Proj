{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpack Kaggle Competition\n",
    "### W207 Final Project - Spring 2025\n",
    "\n",
    "Team: Perry Gabriel, Aurelia Yang\n",
    "\n",
    "University of California, Berkeley\n",
    "\n",
    "## Description\n",
    "\n",
    "In this competition, participants are challenged to develop machine learning models to predict the price of a backpack based on various features. This is a great opportunity to test your skills, learn new techniques, and compete with others in the data science community.\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "Submissions are evaluated on the root mean squared error between the predicted and actual price of the backpack.\n",
    "\n",
    "RMSE is defined as:\n",
    "$$ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} $$\n",
    "\n",
    "where $$y_i$$ is the actual price of the backpack and $$\\hat{y}_i$$ is the predicted price of the backpack.\n",
    "\n",
    "## Data Description\n",
    "\n",
    "The data consists of the following columns:\n",
    "\n",
    "- `id`: A unique identifier for the backpack.\n",
    "- `Brand`: The brand of the backpack.\n",
    "- `Material`: The material of the backpack.\n",
    "- `Size`: The size of the backpack.\n",
    "- `Compartments`: The number of compartments in the backpack.\n",
    "- `Laptop Compartment`: Whether the backpack has a laptop compartment.\n",
    "- `Waterproof`: Whether the backpack is waterproof.\n",
    "- `Style`: The style of the backpack.\n",
    "- `Color`: The color of the backpack.\n",
    "- `Weight Capacity (kg)`: The weight capacity of the backpack in kilograms.\n",
    "- `Price`: The price of the backpack.\n",
    "\n",
    "## Submission File\n",
    "\n",
    "For each `id` in the test set, you must predict the price of the backpack. The file should contain a header and have the following format:\n",
    "\n",
    "```csv\n",
    "id,Price\n",
    "1,100\n",
    "2,200\n",
    "3,300\n",
    "```\n",
    "\n",
    "## Timeline\n",
    "\n",
    "- **Start Date** - February 1, 2025\n",
    "- **Entry Deadline** - Same as the Final Submission Deadline\n",
    "- **Team Merger Deadline** - Same as the Final Submission Deadline\n",
    "- **Final Submission Deadline** - February 28, 2025\n",
    "\n",
    "All deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "This dataset was created by [Kaggle](https://www.kaggle.com/datasets/souradippal/student-bag-price-prediction-dataset) for the purpose of hosting a competition.\n",
    "\n",
    "## Team Members\n",
    "\n",
    "- [Perry Gabriel](https://www.kaggle.com/prgabriel)\n",
    "- [Aurelia Yang](https://www.kaggle.com/aureliayang)\n",
    "\n",
    "## Sections\n",
    "\n",
    "1. [Exploratory Data Analysis](#1.-Exploratory-Data-Analysis)\n",
    "2. [Data Preprocessing](#2.-Data-Preprocessing)\n",
    "3. [Modeling](#3.-Modeling)\n",
    "4. [Evaluation](#4.-Evaluation)\n",
    "5. [Optimization](#5.-Optimization)\n",
    "6. [Final Submission](#6.-Final-Submission)\n",
    "7. [Conclusion](#7.-Conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Data Analysis\n",
    "\n",
    "In this section, we will explore the data to understand its structure and identify any patterns or trends that may be present.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load the Data\n",
    "\n",
    "Let's start by loading the data and taking a look at the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "raw_data_path = '../data/raw/'\n",
    "os.makedirs(raw_data_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment to download the data from Kaggle. This assumes you have the Kaggle API installed and configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c playground-series-s5e2\n",
    "# !unzip playground-series-s5e2 -d ../data/raw/\n",
    "# !pip install -r ../requirement.txt\n",
    "# !rm -rf playground-series-s5e2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "train_df = pd.read_csv(filepath_or_buffer=os.path.join(raw_data_path, 'train.csv'), index_col=0, header=0, sep=',')\n",
    "test_df = pd.read_csv(filepath_or_buffer=os.path.join(raw_data_path, 'test.csv'), index_col=0, header=0, sep=',')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Summary\n",
    "\n",
    "Next, let's take a look at the summary statistics of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the summary statistics of the training data\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the data types of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data types of columns in training dataset\\n{train_df.dtypes}\\n\")\n",
    "print(f\"Data types of columns in testing dataset\\n{test_df.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the shape of the dataset.\n",
    "print(f\"Shape of training data: {train_df.shape}\")\n",
    "print(f\"Shape of testing data: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Visualization\n",
    "\n",
    "We can also create visualizations to better understand the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a pairplot of the training data\n",
    "sns.pairplot(train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, plot a histogram of the price column\n",
    "plt.hist(train_df['Price'], bins=20, edgecolor='black')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Correlation Matrix\n",
    "\n",
    "Finally, let's create a correlation matrix to see how the features are related to each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the numeric columns\n",
    "numeric_cols = train_df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Create a correlation matrix\n",
    "corr = numeric_cols.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "In this section, we will preprocess the data to prepare it for modeling.\n",
    "\n",
    "### 2.1 Missing Values\n",
    "\n",
    "First, let's check for missing values in the data and decide how to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fill in missing values using forward fill method for both train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "train_df.ffill(inplace=True)\n",
    "\n",
    "# Normalize numerical features\n",
    "numerical_cols = train_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "train_df[numerical_cols] = (train_df[numerical_cols] - train_df[numerical_cols].mean()) / train_df[numerical_cols].std()\n",
    "\n",
    "# Convert categorical features to category type\n",
    "categorical_cols = train_df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    train_df[col] = train_df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "test_df.ffill(inplace=True)\n",
    "\n",
    "# Normalize numerical features\n",
    "numerical_cols = test_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "test_df[numerical_cols] = (test_df[numerical_cols] - test_df[numerical_cols].mean()) / test_df[numerical_cols].std()\n",
    "\n",
    "# Convert categorical features to category type\n",
    "categorical_cols = test_df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    test_df[col] = test_df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see the changes\n",
    "train_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets save the data to a new csv file under processed_data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the directory exists, if not, create it\n",
    "processed_file_path = '../data/processed'\n",
    "if not os.path.exists(processed_file_path):\n",
    "    os.makedirs(processed_file_path)\n",
    "\n",
    "# Save the transformed training data\n",
    "train_df.to_csv(processed_file_path + '/train_processed.csv', index=True)\n",
    "processed_train_df = train_df.copy()\n",
    "\n",
    "# Save the transformed testing data\n",
    "test_df.to_csv(processed_file_path + '/test_processed.csv', index=True)\n",
    "processed_test_df = test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: Make a new notebook for the next steps\n",
    "\n",
    "### 2.2 Feature Engineering\n",
    "\n",
    "In this section, we will create new features that may help improve the performance of our models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling\n",
    "\n",
    "In this section, we will select and train machine learning models to predict the price of the backpack.\n",
    "\n",
    "\n",
    "## 4. Evaluation\n",
    "\n",
    "In this section, we will evaluate the performance of our models using various metrics.\n",
    "\n",
    "\n",
    "## 5. Model Optimization\n",
    "\n",
    "In this section, we will optimize the hyperparameters of our models to improve their performance.\n",
    "\n",
    "\n",
    "## 6. Final Submission\n",
    "\n",
    "In this section, we will select the best model and make final predictions on the test set.\n",
    "\n",
    "\n",
    "## 7. Conclusion\n",
    "\n",
    "In this section, we will summarize our findings and discuss the implications of our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
